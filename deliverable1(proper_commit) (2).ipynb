{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from transformers import pipeline\n",
        "\n",
        "def rate_url_validity(user_query: str, url: str) -> dict:\n",
        "    \"\"\"\n",
        "    Evaluates the validity of a given URL by computing various metrics including\n",
        "    domain trust, content relevance, fact-checking, bias, and citation scores.\n",
        "\n",
        "    Args:\n",
        "        user_query (str): The user's original query.\n",
        "        url (str): The URL to analyze.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing scores for different validity aspects.\n",
        "    \"\"\"\n",
        "\n",
        "    # === Step 1: Fetch Page Content ===\n",
        "    try:\n",
        "        response = requests.get(url, timeout=10)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "        page_text = \" \".join([p.text for p in soup.find_all(\"p\")])  # Extract paragraph text\n",
        "    except Exception as e:\n",
        "        return {\"error\": f\"Failed to fetch content: {str(e)}\"}\n",
        "\n",
        "    # === Step 2: Domain Authority Check (Moz API) ===\n",
        "    # Replace with actual Moz API call\n",
        "    domain_trust = 60  # Placeholder value (Scale: 0-100)\n",
        "\n",
        "    # === Step 3: Content Relevance (Semantic Similarity using Hugging Face) ===\n",
        "    model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')  # Changed model\n",
        "    similarity_score = util.pytorch_cos_sim(model.encode(user_query), model.encode(page_text)).item() * 100\n",
        "\n",
        "    # === Step 4: Fact-Checking (Google Fact Check API) ===\n",
        "    fact_check_score = check_facts(page_text)\n",
        "\n",
        "    # === Step 5: Bias Detection (NLP Sentiment Analysis) ===\n",
        "    sentiment_pipeline = pipeline(\"text-classification\", model=\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
        "    sentiment_result = sentiment_pipeline(page_text[:512])[0]  # Process first 512 characters\n",
        "    bias_score = 100 if sentiment_result[\"label\"] == \"POSITIVE\" else 50 if sentiment_result[\"label\"] == \"NEUTRAL\" else 30\n",
        "\n",
        "    # === Step 6: Citation Check (Google Scholar via SerpAPI) ===\n",
        "    citation_count = check_google_scholar(url)\n",
        "    citation_score = min(citation_count * 10, 100)  # Normalize\n",
        "\n",
        "    # === Step 7: Compute Final Validity Score ===\n",
        "    final_score = (\n",
        "        (0.3 * domain_trust) +\n",
        "        (0.3 * similarity_score) +\n",
        "        (0.2 * fact_check_score) +\n",
        "        (0.1 * bias_score) +\n",
        "        (0.1 * citation_score)\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"Domain Trust\": domain_trust,\n",
        "        \"Content Relevance\": similarity_score,\n",
        "        \"Fact-Check Score\": fact_check_score,\n",
        "        \"Bias Score\": bias_score,\n",
        "        \"Citation Score\": citation_score,\n",
        "        \"Final Validity Score\": final_score\n",
        "    }"
      ],
      "metadata": {
        "id": "b0veqYye8N2r"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xrE4SXac-iYQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}